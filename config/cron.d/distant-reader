#
# Periodic job to scrape the public and private carrels into the patron
# database for the web front-end
#
# Since the app user does not have a home directory, running this as
# me (dbrower). This is not ideal.
#
MAILTO=dbrower
PATH=/bin:/sbin:/usr/bin:/usr/sbin:/usr/local/bin:/usr/local/sbin
SHELL=/bin/bash

# sqlite doesn't like having two processes update the database at the same time.
# The public scraping takes ~7 minutes, so schedule the private scraper around that.
0,5,10,15,25,30,35,40,45,55 * * * * dbrower /opt/reader/scan_carrels.sh /data-disk/www/html/library/patrons/
# only run this every 30 minutes
17,47 * * * * dbrower /opt/reader/scan_carrels.sh /data-disk/www/html/library/carrels/ public
